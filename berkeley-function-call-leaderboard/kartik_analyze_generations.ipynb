{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading score/gpt-3.5-turbo-0125-FC/executable_multiple_function_score_pallavi_annotated.json: Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "# first load prompt results\n",
    "# {\"idx\": 3, \"result\": \"[calculate_displacement(initial_velocity=15, acceleration=9.8, time=10)]\", \"input_token_count\": 473, \"output_token_count\": 19, \"latency\": 0.47064781188964844}\n",
    "\n",
    "error_results_df_list = []\n",
    "full_results_df_list = []\n",
    "acc_dict = {'model': [], 'filename': [], 'accuracy': [], 'correct_count': [], 'total_count': []}\n",
    "for model in ['gpt-3.5-turbo-0125', 'gpt-3.5-turbo-0125-FC']:\n",
    "    # model = 'gpt-3.5-turbo-0125'\n",
    "    results_dir = f'score/{model}'\n",
    "    json_files = [f'{results_dir}/{f}' for f in os.listdir(results_dir) if f.endswith('.json')]\n",
    "    for filename in json_files:\n",
    "        with open(filename, 'r') as f:\n",
    "            try:\n",
    "                data = [json.loads(line) for line in f.readlines()]\n",
    "                # skip the accuracy line\n",
    "                df = pd.DataFrame(data[1:])\n",
    "                df['filename'] = filename.split('/')[-1]\n",
    "                error_results_df_list.append(df)\n",
    "                # parse out accuracy_info\n",
    "                acc_info = data[0]\n",
    "                acc_dict['filename'].append(filename.split('/')[-1])\n",
    "                acc_info['model'] = model\n",
    "                for key in acc_info.keys():\n",
    "                    acc_dict[key].append(acc_info[key])\n",
    "            except Exception as e:\n",
    "                print(f'Error reading {filename}: {e}')\n",
    "\n",
    "# now read full results\n",
    "for model in ['gpt-3.5-turbo-0125', 'gpt-3.5-turbo-0125-FC']:\n",
    "    results_dir = f'result/{model}'\n",
    "    json_files = [f'{results_dir}/{f}' for f in os.listdir(results_dir) if f.endswith('.json')]\n",
    "    for filename in json_files:\n",
    "        with open(filename, 'r') as f:\n",
    "            try:\n",
    "                data = [json.loads(line) for line in f.readlines()]\n",
    "                df = pd.DataFrame(data)\n",
    "                df['filename'] = filename.split('/')[-1]\n",
    "                df['model_name'] = model\n",
    "                full_results_df_list.append(df)\n",
    "            except Exception as e:\n",
    "                print(f'Error reading {filename}: {e}')\n",
    "\n",
    "acc_df = pd.DataFrame(acc_dict)\n",
    "acc_df['metric'] = acc_df['filename'].apply(lambda x: x.split('/')[-1].split('.')[0])\n",
    "error_result_df = pd.concat(error_results_df_list)\n",
    "full_result_df = pd.concat(full_results_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>filename</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>executable_multiple_function_score.json</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>executable_multiple_function_score.json</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>executable_parallel_function_score.json</td>\n",
       "      <td>0.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>executable_parallel_function_score.json</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>executable_parallel_multiple_function_score.json</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>executable_parallel_multiple_function_score.json</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>executable_simple_score.json</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>executable_simple_score.json</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>java_score.json</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>java_score.json</td>\n",
       "      <td>0.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>javascript_score.json</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>javascript_score.json</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>multiple_function_score.json</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>multiple_function_score.json</td>\n",
       "      <td>0.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>parallel_function_score.json</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>parallel_function_score.json</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>parallel_multiple_function_score.json</td>\n",
       "      <td>0.435000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>parallel_multiple_function_score.json</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>relevance_score.json</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>relevance_score.json</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>rest_score.json</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>rest_score.json</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>simple_score.json</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>simple_score.json</td>\n",
       "      <td>0.552500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model                                          filename  \\\n",
       "3      gpt-3.5-turbo-0125           executable_multiple_function_score.json   \n",
       "17  gpt-3.5-turbo-0125-FC           executable_multiple_function_score.json   \n",
       "10     gpt-3.5-turbo-0125           executable_parallel_function_score.json   \n",
       "23  gpt-3.5-turbo-0125-FC           executable_parallel_function_score.json   \n",
       "5      gpt-3.5-turbo-0125  executable_parallel_multiple_function_score.json   \n",
       "22  gpt-3.5-turbo-0125-FC  executable_parallel_multiple_function_score.json   \n",
       "11     gpt-3.5-turbo-0125                      executable_simple_score.json   \n",
       "18  gpt-3.5-turbo-0125-FC                      executable_simple_score.json   \n",
       "1      gpt-3.5-turbo-0125                                   java_score.json   \n",
       "19  gpt-3.5-turbo-0125-FC                                   java_score.json   \n",
       "8      gpt-3.5-turbo-0125                             javascript_score.json   \n",
       "12  gpt-3.5-turbo-0125-FC                             javascript_score.json   \n",
       "7      gpt-3.5-turbo-0125                      multiple_function_score.json   \n",
       "21  gpt-3.5-turbo-0125-FC                      multiple_function_score.json   \n",
       "2      gpt-3.5-turbo-0125                      parallel_function_score.json   \n",
       "14  gpt-3.5-turbo-0125-FC                      parallel_function_score.json   \n",
       "0      gpt-3.5-turbo-0125             parallel_multiple_function_score.json   \n",
       "13  gpt-3.5-turbo-0125-FC             parallel_multiple_function_score.json   \n",
       "6      gpt-3.5-turbo-0125                              relevance_score.json   \n",
       "15  gpt-3.5-turbo-0125-FC                              relevance_score.json   \n",
       "9      gpt-3.5-turbo-0125                                   rest_score.json   \n",
       "16  gpt-3.5-turbo-0125-FC                                   rest_score.json   \n",
       "4      gpt-3.5-turbo-0125                                 simple_score.json   \n",
       "20  gpt-3.5-turbo-0125-FC                                 simple_score.json   \n",
       "\n",
       "    accuracy  \n",
       "3   0.720000  \n",
       "17  0.680000  \n",
       "10  0.620000  \n",
       "23  0.720000  \n",
       "5   0.450000  \n",
       "22  0.400000  \n",
       "11  0.780000  \n",
       "18  0.750000  \n",
       "1   0.510000  \n",
       "19  0.530000  \n",
       "8   0.640000  \n",
       "12  0.600000  \n",
       "7   0.720000  \n",
       "21  0.660000  \n",
       "2   0.740000  \n",
       "14  0.860000  \n",
       "0   0.435000  \n",
       "13  0.600000  \n",
       "6   0.600000  \n",
       "15  0.025000  \n",
       "9   0.757143  \n",
       "16  0.757143  \n",
       "4   0.770000  \n",
       "20  0.552500  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df[['model', 'filename', 'accuracy']].sort_values(by=['filename', 'model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-3.5-turbo-0125 : Acc = 66.47058823529412%\n",
      "Model: gpt-3.5-turbo-0125-FC : Acc = 55.76470588235294%\n"
     ]
    }
   ],
   "source": [
    "for model in acc_df['model'].unique():\n",
    "    acc = acc_df[acc_df['model'] == model].correct_count.sum() / acc_df[acc_df['model'] == model].total_count.sum()\n",
    "    print(f'Model: {model} : Acc = {100.0*acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most of the accuracies are comparable, the biggest difference makers are:\n",
    "# 1. relevance_score.json: 60% (prompt) vs 0 (FC)\n",
    "# 2. simple_score.json: 77% (prompt) vs 55% (FC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_name</th>\n",
       "      <th>test_category</th>\n",
       "      <th>valid</th>\n",
       "      <th>error</th>\n",
       "      <th>error_type</th>\n",
       "      <th>prompt</th>\n",
       "      <th>model_result_raw</th>\n",
       "      <th>possible_answer</th>\n",
       "      <th>model_result_decoded</th>\n",
       "      <th>filename</th>\n",
       "      <th>model_result</th>\n",
       "      <th>decoded_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>simple</td>\n",
       "      <td>False</td>\n",
       "      <td>[Invalid syntax. Failed to decode AST. ]</td>\n",
       "      <td>ast_decoder:decoder_failed</td>\n",
       "      <td>{'question': 'What are the roots of the quadra...</td>\n",
       "      <td>[{'solve_quadratic': {'a': 2, 'b': 5, 'c': 3}}]</td>\n",
       "      <td>{'solve_quadratic': {'a': [2], 'b': [5], 'c': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>simple_score.json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>simple</td>\n",
       "      <td>False</td>\n",
       "      <td>[Nested type checking failed for parameter 'in...</td>\n",
       "      <td>type_error:nested</td>\n",
       "      <td>{'question': 'Calculate the area under the cur...</td>\n",
       "      <td>[calculate_area_under_curve(function='x**2', i...</td>\n",
       "      <td>{'calculate_area_under_curve': {'function': ['...</td>\n",
       "      <td>[{'calculate_area_under_curve': {'function': '...</td>\n",
       "      <td>simple_score.json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>simple</td>\n",
       "      <td>False</td>\n",
       "      <td>[Invalid value for parameter 'function': '3*x*...</td>\n",
       "      <td>value_error:string</td>\n",
       "      <td>{'question': 'Calculate the derivative of the ...</td>\n",
       "      <td>[calculate_derivative(function='3*x**2 + 2*x -...</td>\n",
       "      <td>{'calculate_derivative': {'function': ['3x^2 +...</td>\n",
       "      <td>[{'calculate_derivative': {'function': '3*x**2...</td>\n",
       "      <td>simple_score.json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>simple</td>\n",
       "      <td>False</td>\n",
       "      <td>[Invalid syntax. Failed to decode AST. ]</td>\n",
       "      <td>ast_decoder:decoder_failed</td>\n",
       "      <td>{'question': 'Calculate the area under the cur...</td>\n",
       "      <td>[{'name': 'integrate', 'parameters': {'functio...</td>\n",
       "      <td>{'integrate': {'function': ['x^3', 'x**3'], 's...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>simple_score.json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>simple</td>\n",
       "      <td>False</td>\n",
       "      <td>[Invalid value for parameter 'function': '2*x*...</td>\n",
       "      <td>value_error:string</td>\n",
       "      <td>{'question': 'Calculate the derivative of the ...</td>\n",
       "      <td>[calculus.derivative(function='2*x**2', value=...</td>\n",
       "      <td>{'calculus.derivative': {'function': ['2*x^2',...</td>\n",
       "      <td>[{'calculus.derivative': {'function': '2*x**2'...</td>\n",
       "      <td>simple_score.json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id          model_name test_category  valid  \\\n",
       "0   7  gpt-3.5-turbo-0125        simple  False   \n",
       "1  14  gpt-3.5-turbo-0125        simple  False   \n",
       "2  15  gpt-3.5-turbo-0125        simple  False   \n",
       "3  16  gpt-3.5-turbo-0125        simple  False   \n",
       "4  17  gpt-3.5-turbo-0125        simple  False   \n",
       "\n",
       "                                               error  \\\n",
       "0           [Invalid syntax. Failed to decode AST. ]   \n",
       "1  [Nested type checking failed for parameter 'in...   \n",
       "2  [Invalid value for parameter 'function': '3*x*...   \n",
       "3           [Invalid syntax. Failed to decode AST. ]   \n",
       "4  [Invalid value for parameter 'function': '2*x*...   \n",
       "\n",
       "                   error_type  \\\n",
       "0  ast_decoder:decoder_failed   \n",
       "1           type_error:nested   \n",
       "2          value_error:string   \n",
       "3  ast_decoder:decoder_failed   \n",
       "4          value_error:string   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  {'question': 'What are the roots of the quadra...   \n",
       "1  {'question': 'Calculate the area under the cur...   \n",
       "2  {'question': 'Calculate the derivative of the ...   \n",
       "3  {'question': 'Calculate the area under the cur...   \n",
       "4  {'question': 'Calculate the derivative of the ...   \n",
       "\n",
       "                                    model_result_raw  \\\n",
       "0    [{'solve_quadratic': {'a': 2, 'b': 5, 'c': 3}}]   \n",
       "1  [calculate_area_under_curve(function='x**2', i...   \n",
       "2  [calculate_derivative(function='3*x**2 + 2*x -...   \n",
       "3  [{'name': 'integrate', 'parameters': {'functio...   \n",
       "4  [calculus.derivative(function='2*x**2', value=...   \n",
       "\n",
       "                                     possible_answer  \\\n",
       "0  {'solve_quadratic': {'a': [2], 'b': [5], 'c': ...   \n",
       "1  {'calculate_area_under_curve': {'function': ['...   \n",
       "2  {'calculate_derivative': {'function': ['3x^2 +...   \n",
       "3  {'integrate': {'function': ['x^3', 'x**3'], 's...   \n",
       "4  {'calculus.derivative': {'function': ['2*x^2',...   \n",
       "\n",
       "                                model_result_decoded           filename  \\\n",
       "0                                                NaN  simple_score.json   \n",
       "1  [{'calculate_area_under_curve': {'function': '...  simple_score.json   \n",
       "2  [{'calculate_derivative': {'function': '3*x**2...  simple_score.json   \n",
       "3                                                NaN  simple_score.json   \n",
       "4  [{'calculus.derivative': {'function': '2*x**2'...  simple_score.json   \n",
       "\n",
       "  model_result decoded_result  \n",
       "0          NaN            NaN  \n",
       "1          NaN            NaN  \n",
       "2          NaN            NaN  \n",
       "3          NaN            NaN  \n",
       "4          NaN            NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt3_5_fc_relevance_errors = error_result_df[(error_result_df['filename'] == 'relevance_score.json') & (error_result_df['model_name'] == 'gpt-3.5-turbo-0125-FC')]\n",
    "gpt3_5_fc_relevance_results = full_result_df[(full_result_df['filename'] == 'gorilla_openfunctions_v1_test_relevance_result.json') & (full_result_df['model_name'] == 'gpt-3.5-turbo-0125-FC')]\n",
    "gpt3_5_prompt_relevance_errors = error_result_df[(error_result_df['filename'] == 'relevance_score.json') & (error_result_df['model_name'] == 'gpt-3.5-turbo-0125')]\n",
    "gpt3_5_prompt_relevance_results = full_result_df[(full_result_df['filename'] == 'gorilla_openfunctions_v1_test_relevance_result.json') & (full_result_df['model_name'] == 'gpt-3.5-turbo-0125')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(234, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt3_5_fc_relevance_errors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt3_5_prompt_relevance_errors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt3_5_fc_relevance_results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# takeaway - gpt3.5 FC gets relevance results ALMOST ALWAYS WRONG! 234/240 are wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_name</th>\n",
       "      <th>test_category</th>\n",
       "      <th>valid</th>\n",
       "      <th>error</th>\n",
       "      <th>error_type</th>\n",
       "      <th>prompt</th>\n",
       "      <th>model_result_raw</th>\n",
       "      <th>model_result_decoded</th>\n",
       "      <th>possible_answer</th>\n",
       "      <th>filename</th>\n",
       "      <th>model_result</th>\n",
       "      <th>decoded_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>relevance</td>\n",
       "      <td>False</td>\n",
       "      <td>[Valid syntax. Successfully decode AST when it...</td>\n",
       "      <td>relevance_error:decoder_success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relevance_score.json</td>\n",
       "      <td>[{'determine_body_mass_index': '{\"weight\": 10,...</td>\n",
       "      <td>[{'determine_body_mass_index': {'weight': 10, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>relevance</td>\n",
       "      <td>False</td>\n",
       "      <td>[Valid syntax. Successfully decode AST when it...</td>\n",
       "      <td>relevance_error:decoder_success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relevance_score.json</td>\n",
       "      <td>[{'math_sum': '{\"numbers\": [1, 2, 3]}'}, {'mat...</td>\n",
       "      <td>[{'math_sum': {'numbers': [1, 2, 3]}}, {'math_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>relevance</td>\n",
       "      <td>False</td>\n",
       "      <td>[Valid syntax. Successfully decode AST when it...</td>\n",
       "      <td>relevance_error:decoder_success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relevance_score.json</td>\n",
       "      <td>[{'solve_quadratic_equation': '{\"a\": 3, \"b\": -...</td>\n",
       "      <td>[{'solve_quadratic_equation': {'a': 3, 'b': -2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>relevance</td>\n",
       "      <td>False</td>\n",
       "      <td>[Valid syntax. Successfully decode AST when it...</td>\n",
       "      <td>relevance_error:decoder_success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relevance_score.json</td>\n",
       "      <td>[{'find_critical_points': '{\"function\":\"3x + 2...</td>\n",
       "      <td>[{'find_critical_points': {'function': '3x + 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>relevance</td>\n",
       "      <td>False</td>\n",
       "      <td>[Valid syntax. Successfully decode AST when it...</td>\n",
       "      <td>relevance_error:decoder_success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relevance_score.json</td>\n",
       "      <td>[{'find_roots': '{\"a\": 0, \"b\": 1, \"c\": 0}'}, {...</td>\n",
       "      <td>[{'find_roots': {'a': 0, 'b': 1, 'c': 0}}, {'f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id             model_name test_category  valid  \\\n",
       "0   1  gpt-3.5-turbo-0125-FC     relevance  False   \n",
       "1   2  gpt-3.5-turbo-0125-FC     relevance  False   \n",
       "2   3  gpt-3.5-turbo-0125-FC     relevance  False   \n",
       "3   4  gpt-3.5-turbo-0125-FC     relevance  False   \n",
       "4   5  gpt-3.5-turbo-0125-FC     relevance  False   \n",
       "\n",
       "                                               error  \\\n",
       "0  [Valid syntax. Successfully decode AST when it...   \n",
       "1  [Valid syntax. Successfully decode AST when it...   \n",
       "2  [Valid syntax. Successfully decode AST when it...   \n",
       "3  [Valid syntax. Successfully decode AST when it...   \n",
       "4  [Valid syntax. Successfully decode AST when it...   \n",
       "\n",
       "                        error_type prompt model_result_raw  \\\n",
       "0  relevance_error:decoder_success    NaN              NaN   \n",
       "1  relevance_error:decoder_success    NaN              NaN   \n",
       "2  relevance_error:decoder_success    NaN              NaN   \n",
       "3  relevance_error:decoder_success    NaN              NaN   \n",
       "4  relevance_error:decoder_success    NaN              NaN   \n",
       "\n",
       "  model_result_decoded possible_answer              filename  \\\n",
       "0                  NaN             NaN  relevance_score.json   \n",
       "1                  NaN             NaN  relevance_score.json   \n",
       "2                  NaN             NaN  relevance_score.json   \n",
       "3                  NaN             NaN  relevance_score.json   \n",
       "4                  NaN             NaN  relevance_score.json   \n",
       "\n",
       "                                        model_result  \\\n",
       "0  [{'determine_body_mass_index': '{\"weight\": 10,...   \n",
       "1  [{'math_sum': '{\"numbers\": [1, 2, 3]}'}, {'mat...   \n",
       "2  [{'solve_quadratic_equation': '{\"a\": 3, \"b\": -...   \n",
       "3  [{'find_critical_points': '{\"function\":\"3x + 2...   \n",
       "4  [{'find_roots': '{\"a\": 0, \"b\": 1, \"c\": 0}'}, {...   \n",
       "\n",
       "                                      decoded_result  \n",
       "0  [{'determine_body_mass_index': {'weight': 10, ...  \n",
       "1  [{'math_sum': {'numbers': [1, 2, 3]}}, {'math_...  \n",
       "2  [{'solve_quadratic_equation': {'a': 3, 'b': -2...  \n",
       "3  [{'find_critical_points': {'function': '3x + 2...  \n",
       "4  [{'find_roots': {'a': 0, 'b': 1, 'c': 0}}, {'f...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt3_5_fc_relevance_errors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>result</th>\n",
       "      <th>input_token_count</th>\n",
       "      <th>output_token_count</th>\n",
       "      <th>latency</th>\n",
       "      <th>filename</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'determine_body_mass_index': '{\"weight\": 10,...</td>\n",
       "      <td>101</td>\n",
       "      <td>36</td>\n",
       "      <td>0.799414</td>\n",
       "      <td>gorilla_openfunctions_v1_test_relevance_result...</td>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'math_sum': '{\"numbers\": [1, 2, 3]}'}, {'mat...</td>\n",
       "      <td>112</td>\n",
       "      <td>52</td>\n",
       "      <td>1.101193</td>\n",
       "      <td>gorilla_openfunctions_v1_test_relevance_result...</td>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[{'solve_quadratic_equation': '{\"a\": 3, \"b\": -...</td>\n",
       "      <td>113</td>\n",
       "      <td>65</td>\n",
       "      <td>1.267069</td>\n",
       "      <td>gorilla_openfunctions_v1_test_relevance_result...</td>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[{'find_critical_points': '{\"function\":\"3x + 2...</td>\n",
       "      <td>133</td>\n",
       "      <td>23</td>\n",
       "      <td>0.650546</td>\n",
       "      <td>gorilla_openfunctions_v1_test_relevance_result...</td>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[{'find_roots': '{\"a\": 0, \"b\": 1, \"c\": 0}'}, {...</td>\n",
       "      <td>109</td>\n",
       "      <td>61</td>\n",
       "      <td>1.080612</td>\n",
       "      <td>gorilla_openfunctions_v1_test_relevance_result...</td>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                             result  input_token_count  \\\n",
       "0    0  [{'determine_body_mass_index': '{\"weight\": 10,...                101   \n",
       "1    1  [{'math_sum': '{\"numbers\": [1, 2, 3]}'}, {'mat...                112   \n",
       "2    2  [{'solve_quadratic_equation': '{\"a\": 3, \"b\": -...                113   \n",
       "3    3  [{'find_critical_points': '{\"function\":\"3x + 2...                133   \n",
       "4    4  [{'find_roots': '{\"a\": 0, \"b\": 1, \"c\": 0}'}, {...                109   \n",
       "\n",
       "   output_token_count   latency  \\\n",
       "0                  36  0.799414   \n",
       "1                  52  1.101193   \n",
       "2                  65  1.267069   \n",
       "3                  23  0.650546   \n",
       "4                  61  1.080612   \n",
       "\n",
       "                                            filename             model_name  \n",
       "0  gorilla_openfunctions_v1_test_relevance_result...  gpt-3.5-turbo-0125-FC  \n",
       "1  gorilla_openfunctions_v1_test_relevance_result...  gpt-3.5-turbo-0125-FC  \n",
       "2  gorilla_openfunctions_v1_test_relevance_result...  gpt-3.5-turbo-0125-FC  \n",
       "3  gorilla_openfunctions_v1_test_relevance_result...  gpt-3.5-turbo-0125-FC  \n",
       "4  gorilla_openfunctions_v1_test_relevance_result...  gpt-3.5-turbo-0125-FC  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt3_5_fc_relevance_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JESUS CHRIST BFCL! There's a bug in your code.\n",
    "# the ID in the error results is not the same as the idx in the results\n",
    "# the score.json idx is off by 1 from the idx in the results\n",
    "\n",
    "\n",
    "# let's see if we can compare FC vs non-FC for these errors\n",
    "def compare_fc_vs_prompt(fc_errors_df, fc_df, prompt_errors_df, prompt_df, idx=None, verbose=False):\n",
    "    if idx is None:\n",
    "        fc_only_errors = set(fc_errors_df.id.values) - set(prompt_errors_df.id.values)\n",
    "        idx = np.random.choice(list(fc_only_errors))\n",
    "    print(f'Looking at idx: {idx} (WHICH IS SECRETLY) {idx - 1} in the results.json')\n",
    "    print(f\"Error: {fc_errors_df.model_name.unique()[0]}\", fc_errors_df[fc_errors_df['id'] == idx]['error'].item())\n",
    "    print(\"FC Model: \", fc_df[fc_df['idx'] == (idx-1)]['result'].item())\n",
    "\n",
    "    if fc_errors_df[fc_errors_df['id'] == idx].test_category.item() == 'simple':\n",
    "        # check if fc model has multiple function calls which repeat\n",
    "        fc_response = fc_df[fc_df['idx'] == (idx-1)]['result'].item()\n",
    "        print(f\"Num FC responses: {len(fc_response)}\")\n",
    "        if len(fc_response) > 1:\n",
    "            same_bool = [response == fc_response[0] for response in fc_response]\n",
    "            if sum(same_bool) == len(same_bool):\n",
    "                print(f\"!!! FC model repeated the same function call {len(fc_response)} times. !!!\")\n",
    "            else:\n",
    "                print(f\"FC model had multiple different function calls. Weird.\")\n",
    "        \n",
    "\n",
    "    print(\"Prompt Model: \", prompt_df[prompt_df['idx'] == (idx-1)]['result'].item())\n",
    "    if idx in prompt_errors_df.id.values:\n",
    "        print(\"Prompt model also made an error. This is not a clear FC error.\")\n",
    "        print(\"Prompt Error: \", prompt_errors_df[prompt_errors_df['id'] == idx]['error'].item())\n",
    "    else:\n",
    "        print(\"Prompt model got it right.\")\n",
    "\n",
    "    if fc_errors_df[fc_errors_df['id'] == idx]['test_category'].item() == 'relevance':\n",
    "        with open(\"data/gorilla_openfunctions_v1_test_relevance.json\", 'r') as f:\n",
    "            data = [json.loads(line) for line in f.readlines()]\n",
    "            question_df = pd.DataFrame(data)\n",
    "    elif fc_errors_df[fc_errors_df['id'] == idx].test_category.item() == 'simple':\n",
    "        with open(\"data/gorilla_openfunctions_v1_test_simple.json\", 'r') as f:\n",
    "            data = [json.loads(line) for line in f.readlines()]\n",
    "            question_df = pd.DataFrame(data)\n",
    "    else:\n",
    "        raise ValueError(f\"Not implemented for test categories {fc_errors_df[fc_errors_df['id'] == idx].test_category.item()}.\")\n",
    "    \n",
    "    print(\"Question: \", question_df.iloc[idx-1]['question'])\n",
    "    if verbose:\n",
    "        print(json.dumps(question_df.iloc[idx-1]['function'], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at idx: 121 (WHICH IS SECRETLY) 120 in the results.json\n",
      "Error: gpt-3.5-turbo-0125-FC ['Valid syntax. Successfully decode AST when it should not.']\n",
      "FC Model:  [{'caffeine_effect': '{\"caffeine_content\":95,\"drinking_frequency\":\"daily\"}'}]\n",
      "Prompt Model:  NO tools call.\n",
      "Prompt model got it right.\n",
      "Question:  What's the neurological impact of sports on human brain?\n",
      "{\n",
      "  \"name\": \"caffeine_effect\",\n",
      "  \"description\": \"Provide potential neurological impact of caffeine, mainly from coffee, on human brain.\",\n",
      "  \"parameters\": {\n",
      "    \"type\": \"dict\",\n",
      "    \"properties\": {\n",
      "      \"caffeine_content\": {\n",
      "        \"type\": \"float\",\n",
      "        \"description\": \"The amount of caffeine contained in coffee in milligrams.\"\n",
      "      },\n",
      "      \"drinking_frequency\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"How often the individual drinks coffee in a day.\"\n",
      "      },\n",
      "      \"drinking_duration\": {\n",
      "        \"type\": \"integer\",\n",
      "        \"description\": \"For how long the individual has been drinking coffee. Default: 100\"\n",
      "      }\n",
      "    },\n",
      "    \"required\": [\n",
      "      \"caffeine_content\",\n",
      "      \"drinking_frequency\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "compare_fc_vs_prompt(gpt3_5_fc_relevance_errors,\n",
    "                     gpt3_5_fc_relevance_results,\n",
    "                     gpt3_5_prompt_relevance_errors,\n",
    "                     gpt3_5_prompt_relevance_results,\n",
    "                     idx=121,\n",
    "                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"data/gorilla_openfunctions_v1_test_relevance.json\", 'r') as f:\n",
    "#     data = [json.loads(line) for line in f.readlines()]\n",
    "#     question_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at idx: 113 (WHICH IS SECRETLY) 112 in the results.json\n",
      "Error: gpt-3.5-turbo-0125-FC ['Valid syntax. Successfully decode AST when it should not.']\n",
      "FC Model:  [{'geocode_address': '{\"address\":\"New York, USA\"}'}]\n",
      "Prompt Model:  [geocode_address(address='New York')]\n",
      "Prompt model also made an error. This is not a clear FC error.\n",
      "Prompt Error:  ['Valid syntax. Successfully decode AST when it should not.']\n",
      "Question:  What's the current traffic condition in New York?\n",
      "{\n",
      "  \"name\": \"geocode_address\",\n",
      "  \"description\": \"Transforms a description of a location (like a pair of coordinates, an address, or a name of a place) to a location on the Earth's surface.\",\n",
      "  \"parameters\": {\n",
      "    \"type\": \"dict\",\n",
      "    \"properties\": {\n",
      "      \"address\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"The address that needs to be geocoded.\"\n",
      "      },\n",
      "      \"locale\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"Preferred locale for the returned address information. (Optional) Default: None\"\n",
      "      }\n",
      "    },\n",
      "    \"required\": [\n",
      "      \"address\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "compare_fc_vs_prompt(gpt3_5_fc_relevance_errors,\n",
    "                     gpt3_5_fc_relevance_results,\n",
    "                     gpt3_5_prompt_relevance_errors,\n",
    "                     gpt3_5_prompt_relevance_results,\n",
    "                     idx=113,\n",
    "                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at idx: 135 (WHICH IS SECRETLY) 134 in the results.json\n",
      "Error: gpt-3.5-turbo-0125-FC ['Valid syntax. Successfully decode AST when it should not.']\n",
      "FC Model:  [{'calculate_battle_outcome': '{\"battle_name\": \"World Cup 2022 Final\", \"strategy_type\": \"football\"}'}, {'calculate_battle_outcome': '{\"battle_name\": \"World Cup 2022 Final\", \"strategy_type\": \"football\"}'}]\n",
      "Prompt Model:  [This question does not relate to the available function. No function applies.]\n",
      "Prompt model got it right.\n",
      "Question:  Who won the World Cup 2022?\n",
      "{\n",
      "  \"name\": \"calculate_battle_outcome\",\n",
      "  \"description\": \"Predicts the outcome of a historical battle based on the strategies, army size and other influencing factors.\",\n",
      "  \"parameters\": {\n",
      "    \"type\": \"dict\",\n",
      "    \"properties\": {\n",
      "      \"battle_name\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"The name of the historical battle.\"\n",
      "      },\n",
      "      \"strategy_type\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"The strategy employed in the battle.\"\n",
      "      },\n",
      "      \"weather_condition\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"Weather condition during the battle.\",\n",
      "        \"default\": \"snowing\"\n",
      "      }\n",
      "    },\n",
      "    \"required\": [\n",
      "      \"battle_name\",\n",
      "      \"strategy_type\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "compare_fc_vs_prompt(gpt3_5_fc_relevance_errors,\n",
    "                     gpt3_5_fc_relevance_results,\n",
    "                     gpt3_5_prompt_relevance_errors,\n",
    "                     gpt3_5_prompt_relevance_results,\n",
    "                     idx=135,\n",
    "                     verbose=True\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'calculate_battle_outcome',\n",
       " 'description': 'Predicts the outcome of a historical battle based on the strategies, army size and other influencing factors.',\n",
       " 'parameters': {'type': 'dict',\n",
       "  'properties': {'battle_name': {'type': 'string',\n",
       "    'description': 'The name of the historical battle.'},\n",
       "   'strategy_type': {'type': 'string',\n",
       "    'description': 'The strategy employed in the battle.'},\n",
       "   'weather_condition': {'type': 'string',\n",
       "    'description': 'Weather condition during the battle.',\n",
       "    'default': 'snowing'}},\n",
       "  'required': ['battle_name', 'strategy_type']}}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/gorilla_openfunctions_v1_test_relevance.json\", 'r') as f:\n",
    "    data = [json.loads(line) for line in f.readlines()]\n",
    "    question_df = pd.DataFrame(data)\n",
    "\n",
    "question_df.iloc[134].function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^honestly not bad. Pretty innovative way to use an irrelevant function to make it look relevant. Still wrong, but I'm impressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaway: Prompt model understands when the passed functions are irrelevant and says no. But the FC model almost always returns a function call even though it makes no sense and gets Rekt. I suspect this is an issue with the way BFCL is calling the FC model. But will verify after implementing for DBRX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now compare for simple\n",
    "gpt3_5_fc_simple_errors = error_result_df[(error_result_df['filename'] == 'simple_score.json') & (error_result_df['model_name'] == 'gpt-3.5-turbo-0125-FC')]\n",
    "gpt3_5_fc_simple_results = full_result_df[(full_result_df['filename'] == 'gorilla_openfunctions_v1_test_simple_result.json') & (full_result_df['model_name'] == 'gpt-3.5-turbo-0125-FC')]\n",
    "gpt3_5_prompt_simple_errors = error_result_df[(error_result_df['filename'] == 'simple_score.json') & (error_result_df['model_name'] == 'gpt-3.5-turbo-0125')]\n",
    "gpt3_5_prompt_simple_results = full_result_df[(full_result_df['filename'] == 'gorilla_openfunctions_v1_test_simple_result.json') & (full_result_df['model_name'] == 'gpt-3.5-turbo-0125')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at idx: 335 (WHICH IS SECRETLY) 334 in the results.json\n",
      "Error: gpt-3.5-turbo-0125-FC ['Wrong number of functions.']\n",
      "FC Model:  [{'blackjack_check_winner': '{\"player_cards\": [\"A\", \"10\"], \"dealer_cards\": [\"10\", \"9\"], \"ace_value\": 1}'}, {'blackjack_check_winner': '{\"player_cards\": [\"A\", \"10\"], \"dealer_cards\": [\"10\", \"9\"], \"ace_value\": 11}'}]\n",
      "Num FC responses: 2\n",
      "FC model had multiple different function calls. Weird.\n",
      "Prompt Model:  [blackjack.check_winner(player_cards=['A', '10'], dealer_cards=['10', '9'], ace_value=1)]\n",
      "Prompt model got it right.\n",
      "Question:  Check who is the winner in a game of blackjack given player having A and 10, dealer having 10 and 9. The Ace is considered 1.\n",
      "{\n",
      "  \"name\": \"blackjack.check_winner\",\n",
      "  \"description\": \"Checks and determines the winner in a game of blackjack.\",\n",
      "  \"parameters\": {\n",
      "    \"type\": \"dict\",\n",
      "    \"properties\": {\n",
      "      \"player_cards\": {\n",
      "        \"type\": \"array\",\n",
      "        \"items\": {\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"description\": \"Cards held by the player.\"\n",
      "      },\n",
      "      \"dealer_cards\": {\n",
      "        \"type\": \"array\",\n",
      "        \"items\": {\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"description\": \"Cards held by the dealer.\"\n",
      "      },\n",
      "      \"ace_value\": {\n",
      "        \"type\": \"integer\",\n",
      "        \"description\": \"The value considered for the ace card, can be either 1 or 11.\",\n",
      "        \"default\": 11\n",
      "      }\n",
      "    },\n",
      "    \"required\": [\n",
      "      \"player_cards\",\n",
      "      \"dealer_cards\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "compare_fc_vs_prompt(gpt3_5_fc_simple_errors,\n",
    "                     gpt3_5_fc_simple_results,\n",
    "                     gpt3_5_prompt_relevance_errors,\n",
    "                     gpt3_5_prompt_simple_results,\n",
    "                     idx=335,\n",
    "                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at idx: 37 (WHICH IS SECRETLY) 36 in the results.json\n",
      "Error: gpt-3.5-turbo-0125-FC [\"Invalid value for parameter 'unit': 'mi'. Expected one of ['km', '']. Case insensitive.\"]\n",
      "FC Model:  [{'get_shortest_driving_distance': '{\"origin\":\"New York City\",\"destination\":\"Washington D.C.\",\"unit\":\"mi\"}'}]\n",
      "Num FC responses: 1\n",
      "Prompt Model:  [get_shortest_driving_distance(origin='New York City', destination='Washington D.C.')]\n",
      "Prompt model got it right.\n",
      "Question:  Find the shortest driving distance between New York City and Washington D.C.\n"
     ]
    }
   ],
   "source": [
    "compare_fc_vs_prompt(gpt3_5_fc_simple_errors,\n",
    "                     gpt3_5_fc_simple_results,\n",
    "                     gpt3_5_prompt_relevance_errors,\n",
    "                     gpt3_5_prompt_simple_results,\n",
    "                     idx=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at idx: 382 (WHICH IS SECRETLY) 381 in the results.json\n",
      "Error: gpt-3.5-turbo-0125-FC ['Wrong number of functions.']\n",
      "FC Model:  [{'hilton_hotel_check_availability': '{\"location\": \"Paris\", \"check_in_date\": \"2023-04-04\", \"check_out_date\": \"2023-04-08\", \"no_of_adults\": 2}'}, {'hilton_hotel_check_availability': '{\"location\": \"Paris\", \"check_in_date\": \"2023-04-04\", \"check_out_date\": \"2023-04-08\", \"no_of_adults\": 2, \"hotel_chain\": \"Hilton Garden Inn\"}'}]\n",
      "Num FC responses: 2\n",
      "FC model had multiple different function calls. Weird.\n",
      "Prompt Model:  [{'name': 'hilton_hotel.check_availability', 'parameters': {'location': 'Paris', 'check_in_date': '2023-04-04', 'check_out_date': '2023-04-08', 'no_of_adults': 2}}]\n",
      "Prompt model got it right.\n",
      "Question:  Check if any Hilton Hotel is available for two adults in Paris from April 4th to April 8th?\n",
      "{\n",
      "  \"name\": \"hilton_hotel.check_availability\",\n",
      "  \"description\": \"Check hotel availability for a specific location and time frame.\",\n",
      "  \"parameters\": {\n",
      "    \"type\": \"dict\",\n",
      "    \"properties\": {\n",
      "      \"location\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"The city where you want to check hotel availability.\"\n",
      "      },\n",
      "      \"check_in_date\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"The check-in date in the format YYYY-MM-DD.\"\n",
      "      },\n",
      "      \"check_out_date\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"The check-out date in the format YYYY-MM-DD.\"\n",
      "      },\n",
      "      \"no_of_adults\": {\n",
      "        \"type\": \"integer\",\n",
      "        \"description\": \"The number of adults for the hotel booking.\"\n",
      "      },\n",
      "      \"hotel_chain\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"The hotel chain where you want to book the hotel.\",\n",
      "        \"default\": \"Hilton\"\n",
      "      }\n",
      "    },\n",
      "    \"required\": [\n",
      "      \"location\",\n",
      "      \"check_in_date\",\n",
      "      \"check_out_date\",\n",
      "      \"no_of_adults\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "compare_fc_vs_prompt(gpt3_5_fc_simple_errors,\n",
    "                     gpt3_5_fc_simple_results,\n",
    "                     gpt3_5_prompt_relevance_errors,\n",
    "                     gpt3_5_prompt_simple_results,\n",
    "                     idx=382,\n",
    "                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at idx: 381 (WHICH IS SECRETLY) 380 in the results.json\n",
      "Error: gpt-3.5-turbo-0125-FC ['Wrong number of functions.']\n",
      "FC Model:  [{'hotel_booking': '{\"location\": \"Manhattan, New York\", \"room_type\": \"single\", \"duration\": 3, \"start_date\": \"2023-03-10\", \"preferences\": [\"pet_friendly\"]}'}, {'hotel_booking': '{\"location\": \"Manhattan, New York\", \"room_type\": \"single\", \"duration\": 3, \"start_date\": \"2023-03-10\", \"preferences\": [\"pet_friendly\"]}'}]\n",
      "Num FC responses: 2\n",
      "!!! FC model repeated the same function call 2 times. !!!\n",
      "Prompt Model:  [hotel_booking(location='Manhattan, New York', room_type='single', duration=3, start_date='March 10th, 2023', preferences=['pet_friendly'])]\n",
      "Prompt model got it right.\n",
      "Question:  Book a single room at a pet friendly hotel near Manhattan, New York for 3 nights starting from March 10th, 2023.\n",
      "{\n",
      "  \"name\": \"hotel_booking\",\n",
      "  \"description\": \"Books a hotel room given the location, room type, stay duration and any additional preferences.\",\n",
      "  \"parameters\": {\n",
      "    \"type\": \"dict\",\n",
      "    \"properties\": {\n",
      "      \"location\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"The city where you want to book the hotel.\"\n",
      "      },\n",
      "      \"room_type\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"Type of the room required. Options: 'single', 'double', 'deluxe', etc.\"\n",
      "      },\n",
      "      \"duration\": {\n",
      "        \"type\": \"integer\",\n",
      "        \"description\": \"The number of nights you want to book the hotel for.\"\n",
      "      },\n",
      "      \"start_date\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"The date when your stay begins.\"\n",
      "      },\n",
      "      \"preferences\": {\n",
      "        \"type\": \"array\",\n",
      "        \"items\": {\n",
      "          \"type\": \"string\",\n",
      "          \"enum\": [\n",
      "            \"pet_friendly\",\n",
      "            \"gym\",\n",
      "            \"swimming_pool\",\n",
      "            \"free_breakfast\",\n",
      "            \"parking\"\n",
      "          ]\n",
      "        },\n",
      "        \"description\": \"Optional preferences of stay at the hotel. Default to use all if not specified.\"\n",
      "      }\n",
      "    },\n",
      "    \"required\": [\n",
      "      \"location\",\n",
      "      \"room_type\",\n",
      "      \"duration\",\n",
      "      \"start_date\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "compare_fc_vs_prompt(gpt3_5_fc_simple_errors,\n",
    "                     gpt3_5_fc_simple_results,\n",
    "                     gpt3_5_prompt_relevance_errors,\n",
    "                     gpt3_5_prompt_simple_results,\n",
    "                     idx=381,\n",
    "                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at idx: 383 (WHICH IS SECRETLY) 382 in the results.json\n",
      "Error: gpt-3.5-turbo-0125-FC ['Wrong number of functions.']\n",
      "FC Model:  [{'book_hotel': '{\"hotel_name\": \"Hilton Hotel\", \"location\": \"Chicago\", \"room_type\": \"single\", \"start_date\": \"10th December 2022\", \"nights\": 2}'}, {'book_hotel': '{\"hotel_name\": \"Hilton Hotel\", \"location\": \"Chicago\", \"room_type\": \"single\", \"start_date\": \"10th December 2022\", \"nights\": 2}'}]\n",
      "Num FC responses: 2\n",
      "!!! FC model repeated the same function call 2 times. !!!\n",
      "Prompt Model:  [book_hotel(hotel_name='Hilton Hotel', location='Chicago', room_type='single', start_date='10th December 2022', nights=2)]\n",
      "Prompt model got it right.\n",
      "Question:  Book a single room for two nights at the Hilton Hotel in Chicago, starting from 10th December 2022.\n",
      "{\n",
      "  \"name\": \"book_hotel\",\n",
      "  \"description\": \"Book a room of specified type for a particular number of nights at a specific hotel, starting from a specified date.\",\n",
      "  \"parameters\": {\n",
      "    \"type\": \"dict\",\n",
      "    \"properties\": {\n",
      "      \"hotel_name\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"The name of the hotel.\"\n",
      "      },\n",
      "      \"location\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"The city in which the hotel is located.\"\n",
      "      },\n",
      "      \"room_type\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"The type of room to be booked.\"\n",
      "      },\n",
      "      \"start_date\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"The start date for the booking.\"\n",
      "      },\n",
      "      \"nights\": {\n",
      "        \"type\": \"integer\",\n",
      "        \"description\": \"The number of nights for which the booking is to be made.\"\n",
      "      }\n",
      "    },\n",
      "    \"required\": [\n",
      "      \"hotel_name\",\n",
      "      \"location\",\n",
      "      \"room_type\",\n",
      "      \"start_date\",\n",
      "      \"nights\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "compare_fc_vs_prompt(gpt3_5_fc_simple_errors,\n",
    "                     gpt3_5_fc_simple_results,\n",
    "                     gpt3_5_prompt_relevance_errors,\n",
    "                     gpt3_5_prompt_simple_results,\n",
    "                     idx=383,\n",
    "                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun_calls = [{'book_hotel': '{\"hotel_name\": \"Hilton Hotel\", \"location\": \"Chicago\", \"room_type\": \"single\", \"start_date\": \"10th December 2022\", \"nights\": 2}'}, {'book_hotel': '{\"hotel_name\": \"Hilton Hotel\", \"location\": \"Chicago\", \"room_type\": \"single\", \"start_date\": \"10th December 2022\", \"nights\": 2}'}]\n",
    "fun_calls[0] == fun_calls[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at idx: 286 (WHICH IS SECRETLY) 285 in the results.json\n",
      "Error: gpt-3.5-turbo-0125-FC ['Wrong number of functions.']\n",
      "FC Model:  [{'find_concert': '{\"location\": \"Chicago, IL\", \"price\": 100, \"genre\": \"Rock\"}'}, {'find_concert': '{\"location\": \"Chicago, IL\", \"price\": 100, \"genre\": \"Pop\"}'}, {'find_concert': '{\"location\": \"Chicago, IL\", \"price\": 100, \"genre\": \"Country\"}'}]\n",
      "Num FC responses: 3\n",
      "FC model had multiple different function calls. Weird.\n",
      "Prompt Model:  [find_concert(location='Chicago, IL', price=100, genre='Rock')]\n",
      "Prompt model got it right.\n",
      "Question:  Find me a Rock concert in Chicago with ticket availability under $100.\n"
     ]
    }
   ],
   "source": [
    "compare_fc_vs_prompt(gpt3_5_fc_simple_errors,\n",
    "                     gpt3_5_fc_simple_results,\n",
    "                     gpt3_5_prompt_relevance_errors,\n",
    "                     gpt3_5_prompt_simple_results,\n",
    "                     idx=286)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at idx: 128 (WHICH IS SECRETLY) 127 in the results.json\n",
      "Error: gpt-3.5-turbo-0125-FC ['Wrong number of functions.']\n",
      "FC Model:  [{'calculate_NPV': '{\"cash_flows\": [200, 300, 400, 500], \"discount_rate\": 0.1, \"initial_investment\": 2000}'}, {'calculate_NPV': '{\"cash_flows\": [-2000, 200, 300, 400, 500], \"discount_rate\": 0.1}'}]\n",
      "Num FC responses: 2\n",
      "FC model had multiple different function calls. Weird.\n",
      "Prompt Model:  [calculate_NPV(cash_flows=[200,300,400,500], discount_rate=0.1, initial_investment=2000)]\n",
      "Prompt model got it right.\n",
      "Question:  Find the Net Present Value (NPV) of an investment, given cash_flows=[200,300,400,500], a discount rate of 10%, and an initial investment of $2000.\n"
     ]
    }
   ],
   "source": [
    "compare_fc_vs_prompt(gpt3_5_fc_simple_errors,\n",
    "                     gpt3_5_fc_simple_results,\n",
    "                     gpt3_5_prompt_relevance_errors,\n",
    "                     gpt3_5_prompt_simple_results,\n",
    "                     idx=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                              179\n",
       "unique                              25\n",
       "top       [Wrong number of functions.]\n",
       "freq                               155\n",
       "Name: error, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt3_5_fc_simple_errors.error.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The FC model repeats function calls 42/179 times.\n"
     ]
    }
   ],
   "source": [
    "def check_if_funcall_repeats(fc_errors_df, fc_df, prompt_errors_df, prompt_df, idx=None):\n",
    "    if idx is None:\n",
    "        fc_only_errors = set(fc_errors_df.id.values) - set(prompt_errors_df.id.values)\n",
    "        idx = np.random.choice(list(fc_only_errors))\n",
    "    # print(f'Looking at idx: {idx} (WHICH IS SECRETLY) {idx - 1} in the results.json')\n",
    "    # print(f\"Error: {fc_errors_df.model_name.unique()[0]}\", fc_errors_df[fc_errors_df['id'] == idx]['error'].item())\n",
    "    # print(\"FC Model: \", fc_df[fc_df['idx'] == (idx-1)]['result'].item())\n",
    "\n",
    "    if fc_errors_df[fc_errors_df['id'] == idx].test_category.item() == 'simple':\n",
    "        # check if fc model has multiple function calls which repeat\n",
    "        fc_response = fc_df[fc_df['idx'] == (idx-1)]['result'].item()\n",
    "        # print(f\"Num FC responses: {len(fc_response)}\")\n",
    "        if len(fc_response) > 1:\n",
    "            same_bool = [response == fc_response[0] for response in fc_response]\n",
    "            if sum(same_bool) == len(same_bool):\n",
    "                # print(f\"!!! FC model repeated the same function call {len(fc_response)} times. !!!\")\n",
    "                return True\n",
    "            else:\n",
    "                # print(f\"FC model had multiple different function calls. Weird.\")\n",
    "                return False\n",
    "        \n",
    "num_fc_repeats = 0\n",
    "for idx in gpt3_5_fc_simple_errors.id.values:\n",
    "    if check_if_funcall_repeats(gpt3_5_fc_simple_errors,\n",
    "                                gpt3_5_fc_simple_results,\n",
    "                                gpt3_5_prompt_simple_errors,\n",
    "                                gpt3_5_prompt_simple_results,\n",
    "                                idx=idx):\n",
    "        num_fc_repeats += 1\n",
    "print(f\"The FC model repeats function calls {num_fc_repeats}/{gpt3_5_fc_simple_errors.shape[0]} times.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# so it looks like 155/179 errors are due to the FC model trying multiple function calls when it should have just invoked the one function, once. Sometimes (42 times) it repeats the same function call, but quite often (137 times) it just makes multiple function calls. This is not just a parsing issue, it could be a prompting issue/incorrect way to use the openAI api. Not sure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to conver it to the exact \"params\" which the model sees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/workdisk/kartik/gorilla/BFCL-venv/lib/python3.11/site-packages/tree_sitter/__init__.py:36: FutureWarning: Language.build_library is deprecated. Use the new bindings instead.\n",
      "  warn(\"{} is deprecated. Use {} instead.\".format(old, new), FutureWarning)\n",
      "/mnt/workdisk/kartik/gorilla/BFCL-venv/lib/python3.11/site-packages/tree_sitter/__init__.py:36: FutureWarning: Language(path, name) is deprecated. Use Language(ptr, name) instead.\n",
      "  warn(\"{} is deprecated. Use {} instead.\".format(old, new), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from model_handler.handler import BaseHandler\n",
    "from model_handler.model_style import ModelStyle\n",
    "from model_handler.utils import (\n",
    "    convert_to_tool,\n",
    "    convert_to_function_call,\n",
    "    augment_prompt_by_languge,\n",
    "    language_specific_pre_processing,\n",
    "    ast_parse,\n",
    ")\n",
    "from model_handler.constant import (\n",
    "    GORILLA_TO_OPENAPI,\n",
    "    GORILLA_TO_PYTHON,\n",
    "    USER_PROMPT_FOR_CHAT_MODEL,\n",
    "    SYSTEM_PROMPT_FOR_CHAT_MODEL,\n",
    ")\n",
    "from openai import OpenAI\n",
    "import os, time, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-FC model:\n",
    "\n",
    "def compare_fc_vs_prompt(fc_errors_df, fc_df, prompt_errors_df, prompt_df, idx=None, verbose=False):\n",
    "    if idx is None:\n",
    "        fc_only_errors = set(fc_errors_df.id.values) - set(prompt_errors_df.id.values)\n",
    "        idx = np.random.choice(list(fc_only_errors))\n",
    "    print(f'Looking at idx: {idx} (WHICH IS SECRETLY) {idx - 1} in the results.json')\n",
    "    print(f\"Error: {fc_errors_df.model_name.unique()[0]}\", fc_errors_df[fc_errors_df['id'] == idx]['error'].item())\n",
    "    print(\"FC Model: \", fc_df[fc_df['idx'] == (idx-1)]['result'].item())\n",
    "\n",
    "    if fc_errors_df[fc_errors_df['id'] == idx].test_category.item() == 'simple':\n",
    "        # check if fc model has multiple function calls which repeat\n",
    "        fc_response = fc_df[fc_df['idx'] == (idx-1)]['result'].item()\n",
    "        print(f\"Num FC responses: {len(fc_response)}\")\n",
    "        if len(fc_response) > 1:\n",
    "            same_bool = [response == fc_response[0] for response in fc_response]\n",
    "            if sum(same_bool) == len(same_bool):\n",
    "                print(f\"!!! FC model repeated the same function call {len(fc_response)} times. !!!\")\n",
    "            else:\n",
    "                print(f\"FC model had multiple different function calls. Weird.\")\n",
    "        \n",
    "\n",
    "    print(\"Prompt Model: \", prompt_df[prompt_df['idx'] == (idx-1)]['result'].item())\n",
    "    if idx in prompt_errors_df.id.values:\n",
    "        print(\"Prompt model also made an error. This is not a clear FC error.\")\n",
    "        print(\"Prompt Error: \", prompt_errors_df[prompt_errors_df['id'] == idx]['error'].item())\n",
    "    else:\n",
    "        print(\"Prompt model got it right.\")\n",
    "\n",
    "    if fc_errors_df[fc_errors_df['id'] == idx]['test_category'].item() == 'relevance':\n",
    "        with open(\"data/gorilla_openfunctions_v1_test_relevance.json\", 'r') as f:\n",
    "            data = [json.loads(line) for line in f.readlines()]\n",
    "            question_df = pd.DataFrame(data)\n",
    "    elif fc_errors_df[fc_errors_df['id'] == idx].test_category.item() == 'simple':\n",
    "        with open(\"data/gorilla_openfunctions_v1_test_simple.json\", 'r') as f:\n",
    "            data = [json.loads(line) for line in f.readlines()]\n",
    "            question_df = pd.DataFrame(data)\n",
    "    else:\n",
    "        raise ValueError(f\"Not implemented for test categories {fc_errors_df[fc_errors_df['id'] == idx].test_category.item()}.\")\n",
    "    \n",
    "    print(\"Question: \", question_df.iloc[idx-1]['question'])\n",
    "    if verbose:\n",
    "        print(json.dumps(question_df.iloc[idx-1]['function'], indent=2))\n",
    "\n",
    "# canonical example:\n",
    "idx=383\n",
    "fc_errors_row = gpt3_5_fc_simple_errors[gpt3_5_fc_simple_errors['id'] == idx]\n",
    "fc_results_row = gpt3_5_fc_simple_results[gpt3_5_fc_simple_results['idx'] == (idx-1)]\n",
    "prompt_errors_row = gpt3_5_prompt_relevance_errors[gpt3_5_prompt_relevance_errors['id'] == idx]\n",
    "prompt_results_row = gpt3_5_prompt_simple_results[gpt3_5_prompt_simple_results['idx'] == (idx-1)]\n",
    "\n",
    "with open(\"data/gorilla_openfunctions_v1_test_simple.json\", 'r') as f:\n",
    "    data = [json.loads(line) for line in f.readlines()]\n",
    "    question_df = pd.DataFrame(data)\n",
    "\n",
    "question_row = question_df.iloc[idx-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Book a single room for two nights at the Hilton Hotel in Chicago, starting from 10th December 2022.\n",
      "Function: {\n",
      "  \"name\": \"book_hotel\",\n",
      "  \"description\": \"Book a room of specified type for a particular number of nights at a specific hotel, starting from a specified date.\",\n",
      "  \"parameters\": {\n",
      "    \"type\": \"dict\",\n",
      "    \"properties\": {\n",
      "      \"hotel_name\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"The name of the hotel.\"\n",
      "      },\n",
      "      \"location\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"The city in which the hotel is located.\"\n",
      "      },\n",
      "      \"room_type\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"The type of room to be booked.\"\n",
      "      },\n",
      "      \"start_date\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"The start date for the booking.\"\n",
      "      },\n",
      "      \"nights\": {\n",
      "        \"type\": \"integer\",\n",
      "        \"description\": \"The number of nights for which the booking is to be made.\"\n",
      "      }\n",
      "    },\n",
      "    \"required\": [\n",
      "      \"hotel_name\",\n",
      "      \"location\",\n",
      "      \"room_type\",\n",
      "      \"start_date\",\n",
      "      \"nights\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "FC Model Response: [{'book_hotel': '{\"hotel_name\": \"Hilton Hotel\", \"location\": \"Chicago\", \"room_type\": \"single\", \"start_date\": \"10th December 2022\", \"nights\": 2}'}, {'book_hotel': '{\"hotel_name\": \"Hilton Hotel\", \"location\": \"Chicago\", \"room_type\": \"single\", \"start_date\": \"10th December 2022\", \"nights\": 2}'}]\n",
      "Prompt Model Response: [book_hotel(hotel_name='Hilton Hotel', location='Chicago', room_type='single', start_date='10th December 2022', nights=2)]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Question: {question_row['question']}\")\n",
    "print(f\"Function: {json.dumps(question_row['function'], indent=2)}\")\n",
    "print(f\"FC Model Response: {fc_results_row['result'].item()}\")\n",
    "print(f\"Prompt Model Response: {prompt_results_row['result'].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_name</th>\n",
       "      <th>test_category</th>\n",
       "      <th>valid</th>\n",
       "      <th>error</th>\n",
       "      <th>error_type</th>\n",
       "      <th>prompt</th>\n",
       "      <th>model_result_raw</th>\n",
       "      <th>model_result_decoded</th>\n",
       "      <th>possible_answer</th>\n",
       "      <th>filename</th>\n",
       "      <th>model_result</th>\n",
       "      <th>decoded_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>383</td>\n",
       "      <td>gpt-3.5-turbo-0125-FC</td>\n",
       "      <td>simple</td>\n",
       "      <td>False</td>\n",
       "      <td>[Wrong number of functions.]</td>\n",
       "      <td>simple_function_checker:wrong_count</td>\n",
       "      <td>{'question': 'Book a single room for two night...</td>\n",
       "      <td>[{'book_hotel': '{\"hotel_name\": \"Hilton Hotel\"...</td>\n",
       "      <td>[{'book_hotel': {'hotel_name': 'Hilton Hotel',...</td>\n",
       "      <td>{'book_hotel': {'hotel_name': ['Hilton Hotel',...</td>\n",
       "      <td>simple_score.json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id             model_name test_category  valid  \\\n",
       "172  383  gpt-3.5-turbo-0125-FC        simple  False   \n",
       "\n",
       "                            error                           error_type  \\\n",
       "172  [Wrong number of functions.]  simple_function_checker:wrong_count   \n",
       "\n",
       "                                                prompt  \\\n",
       "172  {'question': 'Book a single room for two night...   \n",
       "\n",
       "                                      model_result_raw  \\\n",
       "172  [{'book_hotel': '{\"hotel_name\": \"Hilton Hotel\"...   \n",
       "\n",
       "                                  model_result_decoded  \\\n",
       "172  [{'book_hotel': {'hotel_name': 'Hilton Hotel',...   \n",
       "\n",
       "                                       possible_answer           filename  \\\n",
       "172  {'book_hotel': {'hotel_name': ['Hilton Hotel',...  simple_score.json   \n",
       "\n",
       "    model_result decoded_result  \n",
       "172          NaN            NaN  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_errors_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_category = \"simple\"\n",
    "prompt = fc_errors_row.prompt.item()['question']\n",
    "functions = [question_row['function']]\n",
    "prompt = augment_prompt_by_languge(prompt,test_category)\n",
    "functions = language_specific_pre_processing(functions,test_category,False)\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": SYSTEM_PROMPT_FOR_CHAT_MODEL,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Questions:\"\n",
    "        + USER_PROMPT_FOR_CHAT_MODEL.format(\n",
    "            user_prompt=prompt, functions=str(functions)\n",
    "        ),\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role: system\n",
      "content: \"\n",
      "    You are an expert in composing functions. You are given a question and a set of possible functions. \n",
      "    Based on the question, you will need to make one or more function/tool calls to achieve the purpose. \n",
      "    If none of the function can be used, point it out. If the given question lacks the parameters required by the function,\n",
      "    also point it out. You should only return the function call in tools call sections.\n",
      "    \n",
      "role: user\n",
      "content: Questions:\n",
      "    Questions:Book a single room for two nights at the Hilton Hotel in Chicago, starting from 10th December 2022.\n",
      " Note that the provided function is in Python.\n",
      "Here is a list of functions in JSON format that you can invoke:\n",
      "[{'name': 'book_hotel', 'description': 'Book a room of specified type for a particular number of nights at a specific hotel, starting from a specified date.', 'parameters': {'type': 'dict', 'properties': {'hotel_name': {'type': 'string', 'description': 'The name of the hotel.'}, 'location': {'type': 'string', 'description': 'The city in which the hotel is located.'}, 'room_type': {'type': 'string', 'description': 'The type of room to be booked.'}, 'start_date': {'type': 'string', 'description': 'The start date for the booking.'}, 'nights': {'type': 'integer', 'description': 'The number of nights for which the booking is to be made.'}}, 'required': ['hotel_name', 'location', 'room_type', 'start_date', 'nights']}}]. \n",
      "    Should you decide to return the function call(s),Put it in the format of [func1(params_name=params_value, params_name2=params_value2...), func2(params)]\n",
      "\n",
      "    NO other text MUST be included. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for msg in message:\n",
    "    for key in msg:\n",
    "        print(f\"{key}: {msg[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = fc_errors_row.prompt.item()['question']\n",
    "prompt = augment_prompt_by_languge(prompt, test_category)\n",
    "functions = language_specific_pre_processing(functions, test_category, True)\n",
    "if type(functions) is not list:\n",
    "    functions = [functions]\n",
    "message = [{\"role\": \"user\", \"content\": \"Questions:\" + prompt}]\n",
    "oai_tool = convert_to_tool(\n",
    "    functions, GORILLA_TO_OPENAPI, ModelStyle.OpenAI, test_category, True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role: user\n",
      "content: Questions:Book a single room for two nights at the Hilton Hotel in Chicago, starting from 10th December 2022.\n",
      " Note that the provided function is in Python.\n"
     ]
    }
   ],
   "source": [
    "for msg in message:\n",
    "    for key in msg:\n",
    "        print(f\"{key}: {msg[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'book_hotel',\n",
       "   'description': 'Book a room of specified type for a particular number of nights at a specific hotel, starting from a specified date.',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'hotel_name': {'type': 'string',\n",
       "      'description': 'The name of the hotel.'},\n",
       "     'location': {'type': 'string',\n",
       "      'description': 'The city in which the hotel is located.'},\n",
       "     'room_type': {'type': 'string',\n",
       "      'description': 'The type of room to be booked.'},\n",
       "     'start_date': {'type': 'string',\n",
       "      'description': 'The start date for the booking.'},\n",
       "     'nights': {'type': 'integer',\n",
       "      'description': 'The number of nights for which the booking is to be made.'}},\n",
       "    'required': ['hotel_name',\n",
       "     'location',\n",
       "     'room_type',\n",
       "     'start_date',\n",
       "     'nights']}}}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oai_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nexus-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
